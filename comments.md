## For AdaBoost results :
Threshold tuning improved churn recall substantially (0.51 → 0.81/0.85) at the expense of more false positives (96 → 318/390). This is expected: threshold selection is a policy decision reflecting the cost trade-off between false negatives and false positives, while ROC AUC remains unchanged because it measures ranking quality independent of threshold.


[VAL] Best F1  threshold = 0.497 | F1  = 0.6181
[VAL] Best MCC threshold = 0.495 | MCC = 0.4640
{'test_default_threshold': 0.5, 'test_default_accuracy': 0.801277501774308, 'test_default_precision': 0.6643356643356644, 'test_default_recall': 0.5080213903743316, 'test_default_f1': 0.5757575757575758, 'test_default_roc_auc': 0.8466919837763828, 'test_default_pr_auc': 0.6821733366897488, 'test_default_confusion_matrix': [[939, 96], [184, 190]], 'test_default_classification_report': {'0': {'precision': 0.8361531611754229, 'recall': 0.9072463768115943, 'f1-score': 0.8702502316960148, 'support': 1035.0}, '1': {'precision': 0.6643356643356644, 'recall': 0.5080213903743316, 'f1-score': 0.5757575757575758, 'support': 374.0}, 'accuracy': 0.801277501774308, 'macro avg': {'precision': 0.7502444127555437, 'recall': 0.707633883592963, 'f1-score': 0.7230039037267952, 'support': 1409.0}, 'weighted avg': {'precision': 0.790546529650888, 'recall': 0.801277501774308, 'f1-score': 0.792081137784747, 'support': 1409.0}}}
{'test_f1_threshold': 0.497, 'test_f1_accuracy': 0.7239176721078779, 'test_f1_precision': 0.48792270531400966, 'test_f1_recall': 0.8101604278074866, 'test_f1_f1': 0.6090452261306533, 'test_f1_roc_auc': 0.8466919837763828, 'test_f1_pr_auc': 0.6821733366897488, 'test_f1_confusion_matrix': [[717, 318], [71, 303]], 'test_f1_classification_report': {'0': {'precision': 0.9098984771573604, 'recall': 0.6927536231884058, 'f1-score': 0.7866154690071311, 'support': 1035.0}, '1': {'precision': 0.48792270531400966, 'recall': 0.8101604278074866, 'f1-score': 0.6090452261306533, 'support': 374.0}, 'accuracy': 0.7239176721078779, 'macro avg': {'precision': 0.698910591235685, 'recall': 0.7514570254979462, 'f1-score': 0.6978303475688922, 'support': 1409.0}, 'weighted avg': {'precision': 0.7978907137298137, 'recall': 0.7239176721078779, 'f1-score': 0.7394818488255819, 'support': 1409.0}}}
{'test_mcc_threshold': 0.495, 'test_mcc_accuracy': 0.6841731724627396, 'test_mcc_precision': 0.44992947813822287, 'test_mcc_recall': 0.8529411764705882, 'test_mcc_f1': 0.5891043397968606, 'test_mcc_roc_auc': 0.8466919837763828, 'test_mcc_pr_auc': 0.6821733366897488, 'test_mcc_confusion_matrix': [[645, 390], [55, 319]], 'test_mcc_classification_report': {'0': {'precision': 0.9214285714285714, 'recall': 0.6231884057971014, 'f1-score': 0.7435158501440923, 'support': 1035.0}, '1': {'precision': 0.44992947813822287, 'recall': 0.8529411764705882, 'f1-score': 0.5891043397968606, 'support': 374.0}, 'accuracy': 0.6841731724627396, 'macro avg': {'precision': 0.6856790247833972, 'recall': 0.7380647911338448, 'f1-score': 0.6663100949704764, 'support': 1409.0}, 'weighted avg': {'precision': 0.7962755118894724, 'recall': 0.6841731724627396, 'f1-score': 0.7025294024011082, 'support': 1409.0}}}


